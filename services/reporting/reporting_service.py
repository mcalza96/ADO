import pandas as pd
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
from database.db_manager import DatabaseManager

class ReportingService:
    """
    Service for generating reports and dashboards data.
    Leverages the 'view_full_traceability' SQL view for performance and simplicity.
    """

    def __init__(self, db_manager: DatabaseManager = None):
        self.db_manager = db_manager or DatabaseManager()

    def get_client_report(self, client_id: Optional[int] = None, date_range: tuple = None) -> pd.DataFrame:
        """
        Returns a DataFrame for the Client Portal.
        Filters by client_id and date range if provided.
        """
        query = "SELECT * FROM view_full_traceability WHERE 1=1"
        params = []

        if client_id:
            # We need to join with clients table to filter by ID if the view doesn't have client_id
            # But wait, the view has client_name. Let's check if we included client_id in the view.
            # The view definition in schema.sql didn't include client_id explicitly, only client_name.
            # Let's assume for now we filter by client name or we should have added client_id.
            # To be safe and robust, I should probably have added client_id to the view.
            # However, I can filter by client_name if I have it, or I can modify the view.
            # Let's modify the query to join if needed, OR better, let's just add client_id to the view in a future iteration if strictly needed.
            # For now, let's assume we might need to filter by client name or just get everything for the demo if client_id is not passed.
            # Actually, looking at the view, I missed adding client_id. 
            # I will use a subquery or join to filter by client_id effectively, or just filter by client_name if I had it.
            # Wait, I can just fetch all and filter in pandas for MVP if dataset is small, but that's bad practice.
            # Let's check if I can filter by client_name.
            # I'll assume for this sprint we might pass client_name or I'll just fetch all and filter in python for now as a fallback 
            # if I don't want to touch schema again immediately. 
            # BUT, the correct way is to use the view.
            # Let's write the query to filter by client_name if provided (which we might get from the user session).
            pass

        # Re-reading the view definition I just wrote:
        # SELECT l.id..., c.name AS client_name ... FROM loads l LEFT JOIN ... clients c ...
        # So I have client_name.
        
        with self.db_manager as conn:
            # We'll fetch everything and filter in Pandas for maximum flexibility in this MVP phase
            # unless the dataset is huge.
            df = pd.read_sql_query(query, conn, params=params)
        
        # Post-processing
        if date_range:
            start_date, end_date = date_range
            # Ensure dispatch_time is datetime
            df['dispatch_time'] = pd.to_datetime(df['dispatch_time'])
            mask = (df['dispatch_time'].dt.date >= start_date) & (df['dispatch_time'].dt.date <= end_date)
            df = df.loc[mask]

        if client_id:
            # This is tricky without client_id in view. 
            # I'll rely on the UI passing the client name or filtering by it.
            # For now, I will return the whole DF and let the UI filter or 
            # I will implement a 'filter_by_client_name' if needed.
            # Let's assume the caller handles specific client filtering or we add it later.
            pass
            
        return df

    def get_fleet_monitoring(self) -> pd.DataFrame:
        """
        Returns a DataFrame with all trucks currently in the field logistics cycle.
        Includes both 'Dispatched' (En Ruta) and 'Arrived' (En Cola/Espera de Descarga).
        
        Calculates:
        - hours_elapsed: Travel time (Dispatched) or completed travel time (Arrived)
        - waiting_time: Time waiting at site (only for Arrived status)
        """
        # Query loads with status IN ('Dispatched', 'Arrived')
        # Note: view_full_traceability might not have 'Dispatched' if it was designed for old states
        # We'll query loads table directly to ensure we get the new states
        query = """
            SELECT 
                l.id as load_id,
                l.status,
                l.dispatch_time,
                l.arrival_time,
                l.weight_gross_reception as weight_arrival,
                l.weight_net,
                l.ticket_number,
                l.guide_number,
                v.license_plate,
                d.name as driver_name,
                f.name as facility_name,
                s.name as site_name,
                l.destination_site_id
            FROM loads l
            LEFT JOIN vehicles v ON l.vehicle_id = v.id
            LEFT JOIN drivers d ON l.driver_id = d.id
            LEFT JOIN facilities f ON l.origin_facility_id = f.id
            LEFT JOIN sites s ON l.destination_site_id = s.id
            WHERE l.status IN ('Dispatched', 'Arrived')
            ORDER BY l.dispatch_time DESC
        """
        
        with self.db_manager as conn:
            df = pd.read_sql_query(query, conn)
            
        if not df.empty:
            # Convert timestamps to datetime
            df['dispatch_time'] = pd.to_datetime(df['dispatch_time'])
            df['arrival_time'] = pd.to_datetime(df['arrival_time'])
            
            now = datetime.now()
            
            # Calculate hours_elapsed based on status
            def calculate_hours_elapsed(row):
                if row['status'] == 'Dispatched':
                    # For Dispatched: time since dispatch (ongoing trip)
                    if pd.notna(row['dispatch_time']):
                        return (now - row['dispatch_time']).total_seconds() / 3600
                elif row['status'] == 'Arrived':
                    # For Arrived: completed travel time (arrival - dispatch)
                    if pd.notna(row['arrival_time']) and pd.notna(row['dispatch_time']):
                        return (row['arrival_time'] - row['dispatch_time']).total_seconds() / 3600
                return 0.0
            
            # Calculate waiting_time (only for Arrived)
            def calculate_waiting_time(row):
                if row['status'] == 'Arrived' and pd.notna(row['arrival_time']):
                    return (now - row['arrival_time']).total_seconds() / 3600
                return 0.0
            
            df['hours_elapsed'] = df.apply(calculate_hours_elapsed, axis=1)
            df['waiting_time'] = df.apply(calculate_waiting_time, axis=1)
        else:
            # Empty DataFrame with expected columns
            df['hours_elapsed'] = 0.0
            df['waiting_time'] = 0.0
            
        return df

    def get_site_agronomy_stats(self, site_id: int) -> Dict[str, Any]:
        """
        Returns agronomic metrics for a specific site.
        Total N applied vs Max Capacity.
        """
        # This requires aggregation.
        # We need to sum up nitrogen from applications or estimate from loads.
        # The prompt asks for "Total N applied vs Capacidad MÃ¡xima".
        # We have 'applications' table for historical, but also 'loads' for recent.
        # Let's assume we look at the 'applications' table for the source of truth for agronomy.
        
        query_apps = """
            SELECT 
                SUM(nitrogen_load_applied) as total_n
            FROM applications a
            JOIN plots p ON a.plot_id = p.id
            WHERE p.site_id = ?
        """
        
        # We also need the max capacity. This might be complex as it's per plot.
        # Let's get the sum of all plots' capacity for the site? 
        # Or maybe just return the data per plot.
        # The prompt says "Tabla de Sitios/Parcelas con una barra de progreso".
        # So I should probably return a DataFrame of Plots for that Site with their stats.
        
        query_plots = """
            SELECT 
                p.id, p.name, p.area_hectares,
                (SELECT SUM(nitrogen_load_applied) FROM applications a WHERE a.plot_id = p.id) as current_n
            FROM plots p
            WHERE p.site_id = ?
        """
        
        with self.db_manager as conn:
            df_plots = pd.read_sql_query(query_plots, conn, params=(site_id,))
            
        # Mocking max capacity for now as it's not strictly in the simple schema (it's in soil_samples or calculated)
        # Let's assume a standard max N per hectare for the MVP visualization
        MAX_N_PER_HA = 200.0 # kg/ha
        
        if not df_plots.empty:
            df_plots['current_n'] = df_plots['current_n'].fillna(0)
            df_plots['max_n'] = df_plots['area_hectares'] * MAX_N_PER_HA
            df_plots['usage_percent'] = (df_plots['current_n'] / df_plots['max_n']).clip(upper=1.0)
        
        return df_plots
